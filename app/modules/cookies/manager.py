# -*- coding: utf-8 -*-
"""
Cookiesç®¡ç†å™¨ - ç»Ÿä¸€å¤„ç†å„ç§æ ¼å¼çš„Cookies
"""

import json
import logging
import re
from pathlib import Path
from typing import Dict, List, Optional, Union
from urllib.parse import urlparse

logger = logging.getLogger(__name__)


class CookiesManager:
    """Cookiesç®¡ç†å™¨"""
    
    def __init__(self):
        self.cookies_dir = None
        self._load_config()
    
    def _load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            from ...core.config import get_config
            self.cookies_dir = Path(get_config('app.data_dir', '/app/data')) / 'cookies'
            self.cookies_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ… Cookiesç›®å½•: {self.cookies_dir}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½Cookiesé…ç½®å¤±è´¥: {e}")
    
    def save_cookies(self, website: str, cookies_data: str, format_type: str = 'auto') -> Dict:
        """ä¿å­˜Cookies"""
        try:
            # æ£€æµ‹æ ¼å¼
            if format_type == 'auto':
                format_type = self._detect_format(cookies_data)
            
            # éªŒè¯Cookies
            parsed_cookies = self._parse_cookies(cookies_data, format_type)
            if not parsed_cookies:
                return {'success': False, 'error': 'Cookiesæ ¼å¼æ— æ•ˆ'}
            
            # æ ‡å‡†åŒ–ç½‘ç«™åç§°
            website = self._normalize_website_name(website)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            cookies_file = self.cookies_dir / f"{website}.json"
            
            # å‡†å¤‡ä¿å­˜æ•°æ®
            save_data = {
                'website': website,
                'format': format_type,
                'cookies': parsed_cookies,
                'created_at': self._get_current_timestamp(),
                'updated_at': self._get_current_timestamp(),
                'count': len(parsed_cookies)
            }
            
            # å†™å…¥æ–‡ä»¶
            with open(cookies_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… Cookiesä¿å­˜æˆåŠŸ: {website} ({len(parsed_cookies)}ä¸ª)")
            
            return {
                'success': True,
                'message': f'æˆåŠŸä¿å­˜ {len(parsed_cookies)} ä¸ªCookies',
                'website': website,
                'count': len(parsed_cookies),
                'format': format_type
            }
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜Cookieså¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_cookies(self, website: str) -> Dict:
        """è·å–æŒ‡å®šç½‘ç«™çš„Cookies"""
        try:
            website = self._normalize_website_name(website)
            cookies_file = self.cookies_dir / f"{website}.json"
            
            if not cookies_file.exists():
                return {'success': False, 'error': 'Cookiesä¸å­˜åœ¨'}
            
            with open(cookies_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return {
                'success': True,
                'data': data
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–Cookieså¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def list_cookies(self) -> Dict:
        """åˆ—å‡ºæ‰€æœ‰Cookies"""
        try:
            cookies_list = []
            
            for cookies_file in self.cookies_dir.glob("*.json"):
                try:
                    with open(cookies_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    cookies_list.append({
                        'website': data.get('website', cookies_file.stem),
                        'count': data.get('count', 0),
                        'format': data.get('format', 'unknown'),
                        'created_at': data.get('created_at'),
                        'updated_at': data.get('updated_at'),
                        'file_size': cookies_file.stat().st_size
                    })
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–Cookiesæ–‡ä»¶å¤±è´¥: {cookies_file} - {e}")
            
            # æŒ‰æ›´æ–°æ—¶é—´æ’åº
            cookies_list.sort(key=lambda x: x.get('updated_at', ''), reverse=True)
            
            return {
                'success': True,
                'cookies': cookies_list,
                'total': len(cookies_list)
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºCookieså¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def delete_cookies(self, website: str) -> Dict:
        """åˆ é™¤æŒ‡å®šç½‘ç«™çš„Cookies"""
        try:
            website = self._normalize_website_name(website)
            cookies_file = self.cookies_dir / f"{website}.json"
            
            if not cookies_file.exists():
                return {'success': False, 'error': 'Cookiesä¸å­˜åœ¨'}
            
            cookies_file.unlink()
            logger.info(f"âœ… Cookiesåˆ é™¤æˆåŠŸ: {website}")
            
            return {
                'success': True,
                'message': f'æˆåŠŸåˆ é™¤ {website} çš„Cookies'
            }
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤Cookieså¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def export_cookies(self, website: str, format_type: str = 'netscape') -> Dict:
        """å¯¼å‡ºCookiesä¸ºæŒ‡å®šæ ¼å¼"""
        try:
            cookies_data = self.get_cookies(website)
            if not cookies_data['success']:
                return cookies_data
            
            cookies = cookies_data['data']['cookies']
            
            if format_type == 'netscape':
                content = self._export_netscape(cookies)
            elif format_type == 'json':
                content = json.dumps(cookies, indent=2, ensure_ascii=False)
            else:
                return {'success': False, 'error': f'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}'}
            
            return {
                'success': True,
                'content': content,
                'format': format_type,
                'filename': f"{website}_cookies.{'txt' if format_type == 'netscape' else 'json'}"
            }
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºCookieså¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_cookies_for_ytdlp(self, url: str) -> Optional[str]:
        """ä¸ºyt-dlpè·å–å¯¹åº”ç½‘ç«™çš„Cookiesæ–‡ä»¶è·¯å¾„"""
        try:
            domain = self._extract_domain(url)
            if not domain:
                return None

            logger.info(f"ğŸ” ä¸ºURLæŸ¥æ‰¾cookies: {url} -> åŸŸå: {domain}")

            # å®šä¹‰åŸŸåæ˜ å°„å…³ç³»
            domain_mappings = {
                'youtube.com': ['youtube'],
                'youtu.be': ['youtube'],
                'bilibili.com': ['bilibili'],
                'twitter.com': ['twitter'],
                'x.com': ['twitter'],
                'instagram.com': ['instagram'],
                'tiktok.com': ['tiktok']
            }

            # æŸ¥æ‰¾åŒ¹é…çš„ç½‘ç«™å
            possible_websites = []
            for site_domain, website_names in domain_mappings.items():
                if domain == site_domain or domain.endswith('.' + site_domain):
                    possible_websites.extend(website_names)

            # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰æ˜ å°„ï¼Œä½¿ç”¨åŸŸåæœ¬èº«
            if not possible_websites:
                # ç§»é™¤wwwå‰ç¼€å’Œé¡¶çº§åŸŸå
                clean_domain = domain.replace('www.', '')
                if '.' in clean_domain:
                    possible_websites.append(clean_domain.split('.')[0])
                else:
                    possible_websites.append(clean_domain)

            logger.info(f"ğŸ¯ å¯èƒ½çš„ç½‘ç«™å: {possible_websites}")

            # æŸ¥æ‰¾åŒ¹é…çš„Cookiesæ–‡ä»¶
            for website in possible_websites:
                cookies_file = self.cookies_dir / f"{website}.json"
                if cookies_file.exists():
                    logger.info(f"âœ… æ‰¾åˆ°cookiesæ–‡ä»¶: {cookies_file}")

                    # è½¬æ¢ä¸ºNetscapeæ ¼å¼å¹¶ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                    temp_file = self.cookies_dir / f"{website}_temp.txt"
                    export_result = self.export_cookies(website, 'netscape')

                    if export_result['success']:
                        with open(temp_file, 'w', encoding='utf-8') as f:
                            f.write(export_result['content'])
                        logger.info(f"âœ… ç”Ÿæˆä¸´æ—¶cookiesæ–‡ä»¶: {temp_file}")
                        return str(temp_file)
                    else:
                        logger.warning(f"âš ï¸ å¯¼å‡ºcookieså¤±è´¥: {export_result.get('error')}")

            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„cookiesæ–‡ä»¶ï¼ŒåŸŸå: {domain}")
            return None

        except Exception as e:
            logger.error(f"âŒ è·å–yt-dlp Cookieså¤±è´¥: {e}")
            return None
    
    def _detect_format(self, cookies_data: str) -> str:
        """æ£€æµ‹Cookiesæ ¼å¼ - å¢å¼ºç‰ˆ"""
        cookies_data = cookies_data.strip()

        if not cookies_data:
            return 'empty'

        # JSONæ ¼å¼æ£€æµ‹ (æ›´ä¸¥æ ¼)
        if (cookies_data.startswith('[') and cookies_data.endswith(']')) or \
           (cookies_data.startswith('{') and cookies_data.endswith('}')):
            try:
                data = json.loads(cookies_data)
                # éªŒè¯JSONç»“æ„
                if isinstance(data, list):
                    if all(isinstance(item, dict) and 'name' in item for item in data):
                        return 'json_array'
                    return 'json_invalid'
                elif isinstance(data, dict):
                    if 'name' in data or 'cookies' in data:
                        return 'json_object'
                    return 'json_invalid'
                return 'json_unknown'
            except json.JSONDecodeError:
                return 'json_invalid'

        # Netscapeæ ¼å¼æ£€æµ‹ (æ›´ç²¾ç¡®)
        if '# Netscape HTTP Cookie File' in cookies_data:
            return 'netscape_standard'

        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ ¼å¼
        lines = cookies_data.split('\n')
        tab_lines = [line for line in lines if '\t' in line and not line.strip().startswith('#')]
        if tab_lines:
            # æ£€æŸ¥å­—æ®µæ•°é‡
            field_counts = [len(line.split('\t')) for line in tab_lines]
            if all(count >= 6 for count in field_counts):
                return 'netscape_like'

        # æµè§ˆå™¨å¼€å‘è€…å·¥å…·å¤åˆ¶æ ¼å¼
        if ':' in cookies_data and '\n' in cookies_data:
            lines = [line.strip() for line in cookies_data.split('\n') if line.strip()]
            colon_lines = [line for line in lines if ':' in line and not line.startswith('#')]
            if len(colon_lines) > 0:
                return 'browser_devtools'

        # EditThisCookieæ‰©å±•æ ¼å¼
        if 'domain' in cookies_data.lower() and 'path' in cookies_data.lower():
            return 'extension_format'

        # ç®€å•é”®å€¼å¯¹æ ¼å¼
        if '=' in cookies_data:
            if ';' in cookies_data:
                return 'keyvalue_semicolon'
            elif '\n' in cookies_data:
                return 'keyvalue_newline'
            else:
                return 'keyvalue_single'

        # cURLæ ¼å¼æ£€æµ‹
        if 'Cookie:' in cookies_data or 'cookie:' in cookies_data:
            return 'curl_header'

        return 'unknown'
    
    def _parse_cookies(self, cookies_data: str, format_type: str) -> List[Dict]:
        """è§£æCookiesæ•°æ® - å¢å¼ºç‰ˆ"""
        try:
            logger.info(f"ğŸ” è§£æcookiesæ ¼å¼: {format_type}")

            # JSONæ ¼å¼ç³»åˆ—
            if format_type in ['json', 'json_array', 'json_object']:
                return self._parse_json_cookies(cookies_data)

            # Netscapeæ ¼å¼ç³»åˆ—
            elif format_type in ['netscape', 'netscape_standard', 'netscape_like']:
                return self._parse_netscape_cookies(cookies_data)

            # é”®å€¼å¯¹æ ¼å¼ç³»åˆ—
            elif format_type in ['keyvalue', 'keyvalue_semicolon', 'keyvalue_newline', 'keyvalue_single']:
                return self._parse_keyvalue_cookies(cookies_data)

            # æµè§ˆå™¨å¼€å‘è€…å·¥å…·æ ¼å¼
            elif format_type in ['browser_copy', 'browser_devtools']:
                return self._parse_browser_devtools_cookies(cookies_data)

            # æ‰©å±•æ ¼å¼
            elif format_type == 'extension_format':
                return self._parse_extension_cookies(cookies_data)

            # cURLæ ¼å¼
            elif format_type == 'curl_header':
                return self._parse_curl_cookies(cookies_data)

            # å‘åå…¼å®¹
            elif format_type == 'header':
                return self._parse_keyvalue_cookies(cookies_data)

            else:
                logger.warning(f"âš ï¸ æœªçŸ¥æ ¼å¼ç±»å‹: {format_type}")
                return []

        except Exception as e:
            logger.error(f"âŒ è§£æCookieså¤±è´¥: {e}")
            return []
    
    def _parse_json_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£æJSONæ ¼å¼Cookies"""
        data = json.loads(cookies_data)
        if isinstance(data, list):
            return data
        elif isinstance(data, dict):
            return [data]
        return []
    
    def _parse_netscape_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£æNetscapeæ ¼å¼Cookies"""
        cookies = []
        for line_num, line in enumerate(cookies_data.split('\n'), 1):
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            parts = line.split('\t')
            if len(parts) >= 7:
                domain = parts[0]
                domain_specified = parts[1] == 'TRUE'

                # éªŒè¯åŸŸåå’Œ domain_specified å­—æ®µçš„ä¸€è‡´æ€§
                if domain.startswith('.') and not domain_specified:
                    # ä¿®å¤ä¸ä¸€è‡´çš„æƒ…å†µï¼šåŸŸåä»¥.å¼€å¤´ä½†domain_specifiedæ˜¯FALSE
                    logger.warning(f"ä¿®å¤ç¬¬{line_num}è¡Œcookiesæ ¼å¼ï¼šåŸŸå {domain} ä»¥.å¼€å¤´ä½†domain_specifiedä¸ºFALSE")
                    domain_specified = True
                elif not domain.startswith('.') and domain_specified:
                    # ä¿®å¤ä¸ä¸€è‡´çš„æƒ…å†µï¼šåŸŸåä¸ä»¥.å¼€å¤´ä½†domain_specifiedæ˜¯TRUE
                    logger.warning(f"ä¿®å¤ç¬¬{line_num}è¡Œcookiesæ ¼å¼ï¼šåŸŸå {domain} ä¸ä»¥.å¼€å¤´ä½†domain_specifiedä¸ºTRUE")
                    domain_specified = False

                try:
                    expiration = int(parts[4]) if parts[4] != '0' else 0
                except ValueError:
                    expiration = 0

                cookies.append({
                    'domain': domain,
                    'flag': domain_specified,
                    'path': parts[2],
                    'secure': parts[3] == 'TRUE',
                    'expiration': expiration,
                    'name': parts[5],
                    'value': parts[6] if len(parts) > 6 else ''
                })
            else:
                logger.warning(f"è·³è¿‡ç¬¬{line_num}è¡Œï¼šæ ¼å¼ä¸æ­£ç¡®ï¼Œåªæœ‰{len(parts)}ä¸ªå­—æ®µ")

        return cookies
    
    def _parse_keyvalue_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£æé”®å€¼å¯¹æ ¼å¼Cookies"""
        cookies = []
        # å¤„ç†å¤šè¡Œæˆ–åˆ†å·åˆ†éš”çš„cookies
        cookie_pairs = re.split(r'[;\n]', cookies_data)

        for pair in cookie_pairs:
            pair = pair.strip()
            if '=' in pair:
                name, value = pair.split('=', 1)
                cookies.append({
                    'name': name.strip(),
                    'value': value.strip(),
                    'domain': '',
                    'path': '/',
                    'secure': False,
                    'expiration': 0
                })
        return cookies

    def _parse_browser_devtools_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£ææµè§ˆå™¨å¼€å‘è€…å·¥å…·å¤åˆ¶æ ¼å¼Cookies"""
        cookies = []
        lines = cookies_data.split('\n')

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            if ':' in line:
                parts = line.split(':', 1)
                if len(parts) == 2:
                    name = parts[0].strip()
                    value = parts[1].strip()

                    # è·³è¿‡ç©ºå€¼å’Œæ— æ•ˆåç§°
                    if name and value and not name.startswith('//'):
                        cookies.append({
                            'name': name,
                            'value': value,
                            'domain': '',
                            'path': '/',
                            'secure': False,
                            'expiration': 0
                        })
        return cookies

    def _parse_extension_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£ææµè§ˆå™¨æ‰©å±•å¯¼å‡ºæ ¼å¼"""
        cookies = []
        try:
            # å°è¯•ä½œä¸ºJSONè§£æ
            if cookies_data.strip().startswith('[') or cookies_data.strip().startswith('{'):
                return self._parse_json_cookies(cookies_data)

            # å¦åˆ™æŒ‰è¡Œè§£æ
            lines = cookies_data.split('\n')
            for line in lines:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue

                # æŸ¥æ‰¾é”®å€¼å¯¹
                if '=' in line:
                    name, value = line.split('=', 1)
                    cookies.append({
                        'name': name.strip(),
                        'value': value.strip(),
                        'domain': '',
                        'path': '/',
                        'secure': False,
                        'expiration': 0
                    })
        except Exception as e:
            logger.warning(f"âš ï¸ æ‰©å±•æ ¼å¼è§£æå¤±è´¥: {e}")

        return cookies

    def _parse_curl_cookies(self, cookies_data: str) -> List[Dict]:
        """è§£æcURLæ ¼å¼çš„cookies"""
        cookies = []

        # æå–Cookieå¤´éƒ¨å†…å®¹
        cookie_header = ''
        for line in cookies_data.split('\n'):
            line = line.strip()
            if line.lower().startswith('cookie:'):
                cookie_header = line[7:].strip()  # ç§»é™¤'Cookie:'
                break

        if not cookie_header:
            return cookies

        # è§£æcookieå­—ç¬¦ä¸²
        cookie_pairs = cookie_header.split(';')
        for pair in cookie_pairs:
            pair = pair.strip()
            if '=' in pair:
                name, value = pair.split('=', 1)
                cookies.append({
                    'name': name.strip(),
                    'value': value.strip(),
                    'domain': '',
                    'path': '/',
                    'secure': False,
                    'expiration': 0
                })

        return cookies
    
    def _export_netscape(self, cookies: List[Dict]) -> str:
        """å¯¼å‡ºä¸ºNetscapeæ ¼å¼"""
        lines = ['# Netscape HTTP Cookie File', '# Generated by YT-DLP Web V2', '']

        for cookie in cookies:
            domain = cookie.get('domain', '')

            # ä¿®å¤ domain_specified å­—æ®µé€»è¾‘
            # å¦‚æœåŸŸåä»¥ . å¼€å¤´ï¼Œdomain_specified åº”è¯¥æ˜¯ TRUE
            # å¦‚æœåŸŸåä¸ä»¥ . å¼€å¤´ï¼Œdomain_specified åº”è¯¥æ˜¯ FALSE
            if domain.startswith('.'):
                domain_specified = 'TRUE'
            else:
                domain_specified = 'FALSE'
                # å¦‚æœåŸæ¥çš„ flag å­—æ®µå­˜åœ¨ï¼Œä¼˜å…ˆä½¿ç”¨
                if 'flag' in cookie:
                    domain_specified = 'TRUE' if cookie.get('flag', False) else 'FALSE'

            path = cookie.get('path', '/')
            secure = 'TRUE' if cookie.get('secure', False) else 'FALSE'

            # å¤„ç†è¿‡æœŸæ—¶é—´ï¼Œæ”¯æŒå¤šç§å­—æ®µå
            expiration = cookie.get('expiration', 0)
            if expiration == 0:
                expiration = cookie.get('expirationDate', 0)
            if expiration == 0:
                expiration = cookie.get('expires', 0)

            # ç¡®ä¿è¿‡æœŸæ—¶é—´æ˜¯æ•´æ•°
            try:
                expiration = int(float(expiration))
            except (ValueError, TypeError):
                expiration = 0

            name = cookie.get('name', '')
            value = cookie.get('value', '')

            # ç¡®ä¿åŸŸåæ ¼å¼æ­£ç¡®
            if not domain or not name:
                continue  # è·³è¿‡æ²¡æœ‰åŸŸåæˆ–åç§°çš„cookie

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¤ºä¾‹æ•°æ®
            if 'PLEASE_REPLACE_WITH_REAL_VALUE' in value or 'example_' in value:
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ç¤ºä¾‹æ•°æ®: {name}={value}")

            line = f"{domain}\t{domain_specified}\t{path}\t{secure}\t{expiration}\t{name}\t{value}"
            lines.append(line)

        return '\n'.join(lines)
    
    def _normalize_website_name(self, website: str) -> str:
        """æ ‡å‡†åŒ–ç½‘ç«™åç§°"""
        # ç§»é™¤åè®®å’Œè·¯å¾„ï¼Œåªä¿ç•™åŸŸå
        if '://' in website:
            website = urlparse(website).netloc
        
        # ç§»é™¤wwwå‰ç¼€
        if website.startswith('www.'):
            website = website[4:]
        
        # æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
        website = re.sub(r'[^\w\-.]', '_', website)
        
        return website.lower()
    
    def _extract_domain(self, url: str) -> str:
        """ä»URLæå–åŸŸå"""
        try:
            parsed = urlparse(url)
            domain = parsed.netloc
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain.lower()
        except:
            return ''
    
    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()


# å…¨å±€å®ä¾‹
_cookies_manager = None

def get_cookies_manager() -> CookiesManager:
    """è·å–Cookiesç®¡ç†å™¨å®ä¾‹"""
    global _cookies_manager
    if _cookies_manager is None:
        _cookies_manager = CookiesManager()
    return _cookies_manager
